---
title: Synchronisationsgeschwindigkeit des CDH in Bezug auf die Anforderungen von
  W&W
output:
  html_document: default
  pdf_document: default
---

```{r, include = FALSE}
suppressPackageStartupMessages(library(readr))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(dygraphs))
suppressPackageStartupMessages(library(knitr))

interval = "24 hours"
outlier_threshold <- Inf


f.tmp <- read_lines("e:/temp/post-go-live/server.log")

exceptions <- grepl("Entity exception occured", f.tmp)
cleans <- grepl("No changes detected:|Record saved", f.tmp)
clean_rows <- f.tmp[cleans]

n_nochanges <- sum(grepl("No changes detected:", clean_rows))
n_updates <- sum(grepl("Record saved", clean_rows))

# extracting timestamp, recordid and the time-taken 
timestamp <- str_extract(clean_rows, "\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2},\\d{3}")
recordid <- str_extract(clean_rows, "\\[\\w*\\*.{10,11}\\]")
timetaken <- str_extract(clean_rows, "\\[\\d+ms\\]$") %>%
  str_extract("\\d+")

dt <- data.table(timestamp, recordid, timetaken)
dt[, timetaken := as.numeric(timetaken)]
dt[, timestamp := gsub(",", ".", dt[, timestamp])]
dt[, timestamp := as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%OS")]

# Handling outliers
slowest_updates <- head(dt[order(-timetaken)], n = 50)
slowest_ids <- unique(slowest_updates[, recordid])
outlier <- dt[timetaken > outlier_threshold]
n_outlier <- outlier[, .N]
dt <- dt[timetaken < outlier_threshold]

# Reporting on a by-day basis
timeOffset <- 60 * 60 * 6
by_day <- split(dt, cut(dt[, timestamp] - timeOffset, "day"))
# min(by_day[[2]][, timestamp])
# max(by_day[[2]][, timestamp])

min_by_day <- lapply(by_day, function(x) { min(x[, timetaken])})
max_by_day <- lapply(by_day, function(x) { max(x[, timetaken])})
mean_by_day <- lapply(by_day, function(x) { mean(x[, timetaken])})
median_by_day <- lapply(by_day, function(x) { median(x[, timetaken])})
requests_by_day <- lapply(by_day, function(x) { x[, .N]})
day_start <- lapply(by_day, function(x) { min(x[, timestamp])})
day_end <- lapply(by_day, function(x) { max(x[, timestamp])})
day_length <- lapply(by_day, function(x) { difftime(max(x[, timestamp]), 
                                                    min(x[, timestamp]),
                                                    units = "mins")})

times_by_day <- data.frame("Erster_Request" = do.call("c", day_start),
                           "Letzter_Request" = do.call("c", day_end),
                           "Zeitdifferenz" = as.numeric(do.call("c", day_length)),
                           "Minimum_Dauer" = do.call("c", min_by_day),
                           "Maximum_Dauer" = do.call("c", max_by_day),
                           "Durchschnitt_Dauer" = do.call("c", mean_by_day),
                           "Median_Dauer" = do.call("c", median_by_day),
                           "Requests_pro_Tag" = do.call("c", requests_by_day))
times_by_day$Requests_pro_Minute <- times_by_day$Requests_pro_Tag / times_by_day$Zeitdifferenz


# Calculating ratio to probable validation errors
pve_threshold <- 60
pve <- dt[timetaken < pve_threshold]
pve_ratio <- round(pve[, .N] / dt[, .N] * 100, 1)
  
ts_start <- min(dt[, timestamp], na.rm = TRUE)
ts_end <- max(dt[, timestamp], na.rm = TRUE)

actual_mean <- round(dt[, .N] / as.numeric(difftime(ts_end, ts_start), units = "secs"), 2)

td_min <- min(dt[, timetaken], na.rm = TRUE)
td_max <- max(dt[, timetaken], na.rm = TRUE)
td_mean <- mean(dt[, timetaken], na.rm = TRUE)
td_median <- median(dt[, timetaken], na.rm = TRUE)


p1 <- ggplot(dt, aes(x = timestamp, y = timetaken)) +
  geom_line(size = 1, colour = "blue") +
  scale_x_datetime(breaks = seq(round(min(dt$timestamp), "secs"),
                                round(max(dt$timestamp), "secs"), 
                                by = interval)) +  
  geom_hline(yintercept = td_max, size = 1, colour = "red") +
  geom_hline(yintercept = td_mean, size = 1, colour = "green") +
  geom_hline(yintercept = td_min, size = 1, colour = "pink") +
  ggtitle("Put-Zeiten gemäß server.log") + 
  xlab("Zeitpunkt") +
  ylab("Dauer [ms]") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

dy_p1 <- dygraph(data = dt[, c("timestamp", "timetaken")], 
                 main = "Put-Zeiten gemäß server.logs") %>%
  dyHighlight(highlightCircleSize = 5,
              highlightSeriesBackgroundAlpha = 0.2,
              hideOnMouseOut = FALSE,
              highlightSeriesOpts = list(strokeWidth = 3)) %>%
  dyOptions(maxNumberWidth = 20) %>%
  dyRangeSelector()

p2 <- ggplot(dt, aes(x = timetaken)) +
  ggtitle("Verteilung der Put-Zeiten") + 
  xlab("Put-Dauer [ms]") +
  ylab("Häufigkeit") +
  geom_histogram(bins = 50, fill = "blue") +
  theme_minimal()

props <-
  cut(dt[, timetaken], c(0, 50, 100, 250, 500, 1000, 2000, 5000, Inf), dig.lab = 6) %>%
  table() %>%
  prop.table() %>%
  as.data.frame()
colnames(props) <- c("interval", "freq")
props$freq <- props$freq * 100

# quantile(dt[, timetaken])

p4 <- ggplot(props, aes(x = interval, y = freq)) +
  geom_bar(fill = "blue", stat = "identity") +
  ggtitle("Prozentualer Anteil der Put-Requests je Zeitintervall") + 
  xlab("Zeitintervall") +
  ylab("Prozentualer Anteil der Puts pro Intervall") +
  theme_minimal()

cutvar <- cut(dt[, timestamp], interval)
dt_split <- split(dt, cutvar)
numputs <- unlist(lapply(dt_split, nrow))
dt <- data.table("timeinterval" = as.POSIXct(names(dt_split)), numputs)

nputs_min <- min(dt[numputs > 0, numputs])
nputs_max <- max(dt[numputs > 0, numputs])
nputs_mean <- mean(dt[numputs > 0, numputs])

p3 <- ggplot(dt, aes(x = timeinterval, y = numputs)) +
  geom_bar(size = 1, fill = "blue", stat = "identity") +
  geom_smooth(colour = "yellow", method = "loess") +
  scale_x_datetime(breaks = seq(round(min(dt$timeinterval), "secs"),
                                round(max(dt$timeinterval), "secs"), 
                                by = interval)) +  
  geom_hline(yintercept = nputs_max, size = 1, colour = "green") +
#  annotate("text", x = 100, y = nputs_max + 1, label = nputs_max) +
  geom_hline(yintercept = nputs_mean, size = 1, colour = "pink") +
#  annotate("text", x = 100, y = nputs_mean + 1, label = nputs_mean) +
  geom_hline(yintercept = nputs_min, size = 1, colour = "red") +
#  annotate("text", x = 100, y = nputs_min + 1, label = nputs_min) +
#  scale_x_discrete(breaks = NULL) +
  ggtitle(paste0("Absolute Anzahl der Puts je Zeitinterval (", interval, ")")) +
  xlab("Zeit") +
  ylab("Anzahl der Puts") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Compare actual to target
goal <- data.frame(x = c("Vorgabe", "Ist"),
                   y = c(2, actual_mean))

goal$x <- factor(goal$x, levels = c("Vorgabe", "Ist"))

colour_ist = ifelse(actual_mean < 2, "red1", "lawngreen")

pg <- ggplot(goal, aes(x = x, y = y, fill = x)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = y), vjust = -0.4) +
  theme_minimal() + 
  theme(legend.position = "none", 
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(colour = "grey", size = .1)) +
  ylab("") +
  xlab("") +
  ggtitle("Requests pro Sekunde") + 
  scale_fill_manual("legend", values = c("Ist" = colour_ist, "Vorgabe" = "skyblue"))
```

\vspace*{5\baselineskip} 

# Ergebnis
```{r, echo = FALSE}
pg
```
\pagebreak

# Grundlage der Messung
Tatsächliche Änderungsnachrichten nach dem Go-Live

### Umgebung
PU

### Software-Stand
* CDH 16.2.141, Config 16.2.115 incl. Virtual Services Patch
* wildcard-deletes aktiv

### Datenbestand
ca. 25,9 Mio. Quelldatensätze (46,7 Mio. incl. Golden Records)


```{r, echo = FALSE}
paste("Beginn der Messung", ts_start)
paste("Ende der Messung", ts_end)
paste("Anzahl gemessener Update-Requests:", length(clean_rows))
paste("Tatsächliche Updates:", n_updates)
paste("Requests ohne Änderungen:", n_nochanges)
paste("Vermutlicher Anteil von Updates mit Validierungsfehlern (<", pve_threshold, "ms):", pve_ratio, "%")
```
### Die langsamsten Requests
```{r, echo = FALSE}
kable(slowest_updates)
```

### die Ordnungsbegriffe der langsamsten Requests
```{r, echo = FALSE}
kable(slowest_ids)
```

### Ausreißer
```{r, echo = FALSE}
paste0("Anzahl ausgeschlossener Ausreißer (mit Zeiten > ", outlier_threshold, " ms): ", 
       n_outlier, 
       " (bzw. ",
       round((n_outlier / n_updates * 100), 1),
       "%)")
outlier
```

\pagebreak

# Auswertung pro Tag
```{r, echo = FALSE}
kable(times_by_day[, c(4:9)])
```

\pagebreak

# Darstellung auf Basis der tatsächlich verarbeiteten Requests pro Zeitintervall
```{r, echo = FALSE}
paste("Zeitintervall:", interval)
paste("Größte Anzahl von Requests pro Zeitintervall:", nputs_max)
paste("Geringste Anzahl von Requests pro Zeitintervall:", nputs_min)
paste("Durchschnittliche Anzahl von Requests pro Zeitintervall:", round(nputs_mean, 1))
p3
```

\pagebreak

# Auswertung auf Basis der im Log-File vermerkten Zeiten (Zeitdauer der einzelnen Requests)
```{r, echo = FALSE}
paste("Schnellster Request:", td_min, "ms")
paste("Langsamster Request:", td_max, "ms")
paste("Durschnittliche Request-Zeit:", round(td_mean, 2), "ms")
paste("Median:", td_median, "ms")
p1
```


```{r, echo = FALSE}
dy_p1
```

```{r, echo = FALSE}
p4
p2
```
