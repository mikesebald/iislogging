---
title: Synchronisationsgeschwindigkeit des CDH in Bezug auf die Anforderungen von
  W&W
output:
  html_document: default
  pdf_document: default
---

```{r, include = FALSE}
suppressPackageStartupMessages(library(readr))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(data.table))

interval = "1 min"

f.tmp <- read_lines("e:/temp/vasv/server-2018-03-21.log")

exceptions <- grepl("Entity exception occured", f.tmp)
cleans <- grepl("No changes detected:|Record saved", f.tmp)
clean_rows <- f.tmp[cleans]

n_nochanges <- sum(grepl("No changes detected:", clean_rows))
n_updates <- sum(grepl("Record saved", clean_rows))
n_exceptions <- sum(exceptions)

# extracting the timestamp and the time-taken 
timestamp <- str_extract(clean_rows, "\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2},\\d{3}")
timetaken <- str_extract(clean_rows, "\\[\\d+ms\\]$") %>%
  str_extract("\\d+")

dt <- as.data.table(cbind(timestamp, timetaken))
dt[, timetaken := as.numeric(timetaken)]
dt[, timestamp := gsub(",", ".", dt[, timestamp])]
dt[, timestamp := as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%OS")]

# Handling outliers
#View(dt[order(-timetaken)])
outlier_threshold <- Inf
outlier <- dt[timetaken > outlier_threshold]
n_outlier <- outlier[, .N]
dt <- dt[timetaken < outlier_threshold]
outlier_tt <- paste0("\\[", outlier[, timetaken], "ms\\]", collapse = "|")
outlier_lines <- grepl(outlier_tt, f.tmp)

ts_start <- min(dt[, timestamp], na.rm = TRUE)
ts_end <- max(dt[, timestamp], na.rm = TRUE)

td_min <- min(dt[, timetaken], na.rm = TRUE)
td_max <- max(dt[, timetaken], na.rm = TRUE)
td_mean <- mean(dt[, timetaken], na.rm = TRUE)
td_median <- median(dt[, timetaken], na.rm = TRUE)


p1 <- ggplot(dt, aes(x = timestamp, y = timetaken)) +
  geom_line(size = 1, colour = "blue") +
  #  scale_x_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = FALSE)) +
  geom_hline(yintercept = td_max, size = 1, colour = "red") +
  geom_hline(yintercept = td_mean, size = 1, colour = "green") +
  geom_hline(yintercept = td_min, size = 1, colour = "pink") +
  ggtitle("Put-Zeiten gemäß server.log") + 
  xlab("Zeitpunkt") +
  ylab("Dauer [ms]") +
  theme_minimal()

p2 <- ggplot(dt, aes(x = timetaken)) +
  ggtitle("Verteilung der Put-Zeiten") + 
  xlab("Put-Dauer [ms]") +
  ylab("Häufigkeit") +
  geom_histogram(bins = 50, fill = "blue") +
  theme_minimal()

props <-
  cut(dt[, timetaken], c(0, 50, 100, 250, 500, 1000, 2000, 5000), dig.lab = 6) %>%
  table() %>%
  prop.table() %>%
  as.data.frame()
colnames(props) <- c("interval", "freq")
props$freq <- props$freq * 100

quantile(dt[, timetaken])

  
p4 <- ggplot(props, aes(x = interval, y = freq)) +
  geom_bar(fill = "blue", stat = "identity") +
  ggtitle("Prozentualer Anteil der Put-Requests je Zeitintervall") + 
  xlab("Zeitintervall") +
  ylab("Prozentualer Anteil der Puts pro Intervall") +
  theme_minimal()

cutvar <- cut(dt[, timestamp], interval)
dt_split <- split(dt, cutvar)
numputs <- unlist(lapply(dt_split, nrow))
dt <- data.table("timeinterval" = as.POSIXct(names(dt_split)), numputs)

nputs_min <- min(dt[numputs > 0, numputs])
nputs_max <- max(dt[numputs > 0, numputs])
nputs_mean <- mean(dt[numputs > 0, numputs])

p3 <- ggplot(dt, aes(x = timeinterval, y = numputs)) +
  geom_bar(size = 1, fill = "blue", stat = "identity") +
  geom_smooth(colour = "yellow") +
  scale_x_datetime(breaks = seq(round(min(dt$timeinterval), "secs"),
                                round(max(dt$timeinterval), "secs"), 
                                by = "5 mins")) +  
  geom_hline(yintercept = nputs_max, size = 1, colour = "green") +
#  annotate("text", x = 100, y = nputs_max + 1, label = nputs_max) +
  geom_hline(yintercept = nputs_mean, size = 1, colour = "pink") +
#  annotate("text", x = 100, y = nputs_mean + 1, label = nputs_mean) +
  geom_hline(yintercept = nputs_min, size = 1, colour = "red") +
#  annotate("text", x = 100, y = nputs_min + 1, label = nputs_min) +
#  scale_x_discrete(breaks = NULL) +
  ggtitle(paste0("Absolute Anzahl der Puts je Zeitinterval (", interval, ")")) +
  xlab("Zeit") +
  ylab("Anzahl der Puts") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Determine the number of seconds of the chose time-interval to correctly calculate records/second
seconds_factor <- as.numeric(difftime(as.POSIXct(levels(cutvar)[2], format = "%Y-%m-%d %H:%M:%OS"), as.POSIXct(levels(cutvar)[1], format = "%Y-%m-%d %H:%M:%OS"), units = "secs"))
ist <- round((nputs_mean / seconds_factor), 2)
goal <- data.frame(x = c("Vorgabe", "Ist"),
                   y = c(2, ist))

goal$x <- factor(goal$x, levels = c("Vorgabe", "Ist"))

colour_ist = ifelse(ist < 2, "red1", "lawngreen")

pg <- ggplot(goal, aes(x = x, y = y, fill = x)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = y), vjust = -0.4) +
  theme_minimal() + 
  theme(legend.position = "none", 
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(colour = "grey", size = .1)) +
  ylab("") +
  xlab("") +
  ggtitle("Requests pro Sekunde") + 
  scale_fill_manual("legend", values = c("Ist" = colour_ist, "Vorgabe" = "skyblue"))
```

\vspace*{5\baselineskip} 

# Ergebnis
```{r, echo = FALSE}
pg
```
\pagebreak

# Grundlage der Messung
Änderungen über MQSeries

### Testumgebung
vasv

### Software-Stand
CDH 16.2.140, Config 16.2.114 incl. Virtual Services Patch

### Datenbestand
ca. 25,9 Mio. Quelldatensätze (46,7 Mio. incl. Golden Records)

_Hinweis:_ "Leerlaufzeiten" (also Zeitintervalle ohne Requests) sind bei der Berechnung der Werte explizit ausgeschlossen.

```{r, echo = FALSE}
paste("Beginn der Messung", ts_start)
paste("Ende der Messung", ts_end)
paste("Anzahl gemessener Update-Requests:", length(clean_rows))
paste("Tatsächliche Updates:", n_updates)
paste("Requests ohne Änderungen:", n_nochanges)
paste("Fehlerhafte Requests:", n_exceptions)
```

### Ausreisser
```{r, echo=FALSE}
paste0("Anzahl ausgeschlossener Ausreißer (mit Zeiten > ", outlier_threshold, " ms): ", 
       n_outlier, 
       " (bzw. ",
       round((n_outlier / n_updates * 100), 1),
       "%)")
f.tmp[outlier_lines]
```

\pagebreak

# Darstellung auf Basis der tatsächlich verarbeiteten Requests pro Zeitintervall
```{r, echo = FALSE}
paste("Zeitintervall:", interval)
paste("Größte Anzahl von Requests pro Zeitintervall:", nputs_max)
paste("Geringste Anzahl von Requests pro Zeitintervall:", nputs_min)
paste("Durchschnittliche Anzahl von Requests pro Zeitintervall:", round(nputs_mean, 1))
p3
```

\pagebreak

# Auswertung auf Basis der im Log-File vermerkten Zeiten (Zeitdauer der einzelnen Requests)
```{r, echo = FALSE}
paste("Schnellster Request:", td_min, "ms")
paste("Langsamster Request:", td_max, "ms")
paste("Durschnittliche Request-Zeit:", round(td_mean, 2), "ms")
paste("Median:", td_median, "ms")
p1
p4
p2
```
